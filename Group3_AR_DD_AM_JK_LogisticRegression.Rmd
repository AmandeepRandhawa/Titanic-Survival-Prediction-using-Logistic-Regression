---
title: "Group3_AR_DD_JK_AM_LogisticsRegression"
author: 'Group 3: Amandeep Randhawa, Dimple Dhawan, Athira Mohandas, Jyotsana Kumari'
date: "2025-06-19"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r}
# Titanic Logistic Regression Analysis with Visual Interpretation

# -------------------
# Load required libraries
# -------------------
library(dplyr)
library(ggplot2)
library(corrplot)
library(caret)
library(ggmosaic)
library(ggalluvial)
library(gmodels)  

```

```{r}
# -------------------
# Load and Prepare Data
# -------------------
train <- read.csv("train.csv")
test <- read.csv("test.csv")
gender_submission <- read.csv("gender_submission.csv")

# Impute missing values
train$Age[is.na(train$Age)] <- mean(train$Age, na.rm = TRUE)
test$Age[is.na(test$Age)] <- mean(test$Age, na.rm = TRUE)
test$Fare[is.na(test$Fare)] <- mean(test$Fare, na.rm = TRUE)

# Convert to factor
train$Sex <- as.factor(train$Sex)
test$Sex <- as.factor(test$Sex)
train$Survived <- as.factor(train$Survived)

# Feature engineering
train$FamilySize <- train$SibSp + train$Parch + 1


```

```{r}

# -------------------
# Model Training
# -------------------
dataset1_train <- train %>% select(Survived, Pclass, Sex, Age, SibSp, Parch, Fare)
Titanic_model <- glm(Survived ~ ., data = dataset1_train, family = binomial)
summary(Titanic_model)
#Inference based on the above model
#
#Estimate,Standard Error and Z value based on each feature or column and overall are listed
#Pvalue which is less than 0.05, then those features or column are relevant in logistic regression
#Based on the above point overall Intercept(<2e-16), is less than 0.05, so this model is statistically significant
#For Pclass,Sexmale,Age,SibSp are less than 0.05, which means those columns are statistically significant and have strong relationship.
#Fare and Parch are not statistically significant
#Null deviance indicates to what extend intercept only model fit data and high-value is low fit.
#Residual deviance is the deviance of the fitted model with predictors included,and also shows how well data is fitted compared to null model
#Reduction of residual deviance from Null deviance indicate,how much better our model is than just using the intercept.
#Our model improved the fit significantly (from 1186.66 → 788.73), suggesting that your predictors have strong explanatory power.
#The difference in deviance (~398) with 6 degrees of freedom[number of observations-1] (890–884) suggests a statistically significant improvement.
# Women had a higher chance of surviving than males.    Pclass 1 had a highest chance of surviving over P2 and p3 had lowest chance of survival,

```




```{r}

# Predictions
Predict <- predict(Titanic_model, type = "response", newdata = test)
test$Survived <- as.numeric(Predict >= 0.5)
test$Predicted_Prob <- Predict


```

```{r}



# Multi-variable cross table: Sex × Pclass × Survived
cat("\nCross Table: Sex × Pclass × Survived\n")
table_sex_class_survived <- table(train$Sex, train$Pclass, train$Survived)
print(table_sex_class_survived)

```

```{r}
# Cross Table
cat("\nCross Table: Sex vs Survived\n")
CrossTable(train$Sex, train$Survived, prop.chisq = FALSE, prop.t = FALSE, prop.r = TRUE, prop.c = TRUE)

# Age Grouping
train$AgeGroup <- cut(train$Age, breaks = c(0, 12, 18, 35, 60, 100), labels = c("Child", "Teen", "YoungAdult", "Adult", "Senior"))
cat("\nCross Table: Age Group vs Survived\n")
CrossTable(train$AgeGroup, train$Survived, prop.chisq = FALSE)
```

```{r}
# -------------------
# Visualizations and Interpretations
# -------------------

# Distribution of predicted survival probabilities
# This histogram shows how confident the model is in its predictions.
# A bimodal distribution would indicate clear classification; a uniform one suggests uncertainty.
ggplot(test, aes(x = Predicted_Prob)) +
  geom_histogram(binwidth = 0.05, fill = "skyblue", color = "black") +
  labs(title = "Distribution of Predicted Survival Probabilities",
       x = "Predicted Probability of Survival",
       y = "Number of Passengers") +
  theme_minimal()

```


```{r}
# Predicted Survival Count (0 vs 1)
# Bar chart showing number of passengers predicted to survive or not.
# Helps assess the model's output balance and any prediction skew.
ggplot(test, aes(x = factor(Survived))) +
  geom_bar(fill = "lightgreen", color = "black") +
  labs(title = "Predicted Survival Outcome",
       x = "Survived (0 = No, 1 = Yes)",
       y = "Passenger Count") +
  theme_minimal()

```


```{r}
# Survival by Gender
# Female passengers had much higher survival rates.
# Reflects the "women and children first" evacuation policy.
ggplot(train, aes(x = Sex, fill = factor(Survived))) +
  geom_bar(position = "dodge") +
  labs(title = "Survival Count by Gender", x = "Gender", fill = "Survived")

```


```{r}
# Survival by Class
# Higher class (especially 1st class) passengers had better survival odds.
# Indicates the impact of socioeconomic status on access to lifeboats.
ggplot(train, aes(x = factor(Pclass), fill = factor(Survived))) +
  geom_bar(position = "fill") +
  labs(title = "Survival Rate by Passenger Class", x = "Passenger Class", y = "Proportion", fill = "Survived")

```

```{r}
# Age Distribution by Survival
# Younger passengers, particularly children, had better survival chances.
# Highlights prioritization based on age.
ggplot(train, aes(x = Age, fill = factor(Survived))) +
  geom_histogram(binwidth = 5, position = "identity", alpha = 0.5) +
  labs(title = "Age Distribution by Survival", x = "Age", fill = "Survived")

```



```{r}
# Correlation Matrix
# Identifies relationships among numeric variables like Fare, Age, SibSp, etc.
# Useful to detect multicollinearity for modeling.
# Select and ensure all variables are numeric
numeric_vars <- train %>%
  select(Age, SibSp, Parch, Fare, Survived) %>%
  mutate(across(everything(), as.numeric))

# Plot correlation matrix
corrplot(cor(numeric_vars, use = "complete.obs"), 
         method = "circle", 
         title = "Correlation Matrix", 
         tl.cex = 0.8)

```



```{r}

# Family Size vs Survival
# Shows survival trends based on number of family members aboard.
# Small families had better odds; very large or solo travelers fared worse.
ggplot(train, aes(x = FamilySize, fill = factor(Survived))) +
  geom_bar(position = "dodge") +
  labs(title = "Survival Count by Family Size", x = "Family Size", fill = "Survived")

```



```{r}
# Confusion Matrix
# Quantifies how well the model performs on training data.
# Displays true vs. predicted classifications.
train$Predicted <- as.numeric(predict(Titanic_model, type = "response") >= 0.5)
confusionMatrix(factor(train$Predicted), factor(train$Survived))

```



```{r}
# Age vs Fare by Gender and Survival
# Scatter plot reveals patterns in survival based on age, fare paid, and gender.
# Higher fare and younger age often correlate with higher survival.
ggplot(train, aes(x = Age, y = Fare, color = Sex, shape = factor(Survived))) +
  geom_point(alpha = 0.7, size = 3) +
  labs(title = "Age vs Fare by Gender and Survival", x = "Age", y = "Fare", shape = "Survived") +
  scale_shape_manual(values = c(4, 16)) +
  theme_minimal()

```

```{r}


# Faceted Histogram by Class and Gender
# Shows how survival varies across age groups within class and gender.
# Useful for spotting granular trends within subgroups.
ggplot(train, aes(x = Age, fill = factor(Survived))) +
  geom_histogram(binwidth = 5, alpha = 0.6, position = "identity") +
  facet_grid(Sex ~ Pclass) +
  labs(title = "Age Distribution by Survival, Gender, and Class", x = "Age", fill = "Survived") +
  theme_minimal()

```

```{r}
# Violin Plot: Fare vs Class
# Depicts the distribution and density of fare within each class and survival group.
# Reveals class-based inequalities in fare distribution.
ggplot(train, aes(x = factor(Pclass), y = Fare, fill = factor(Survived))) +
  geom_violin(trim = FALSE, alpha = 0.6) +
  facet_wrap(~Sex) +
  labs(title = "Fare Distribution by Class, Gender, and Survival", x = "Passenger Class", y = "Fare", fill = "Survived") +
  theme_minimal()

```

```{r}
# Heatmap: Survival by Family Size & Class
# Visual summary of survival rate based on class and family size combination.
# Identifies sweet spots and at-risk groups.
heatmap_data <- train %>%
  group_by(Pclass, FamilySize) %>%
  summarise(SurvivalRate = mean(as.numeric(as.character(Survived))), .groups = 'drop')

ggplot(heatmap_data, aes(x = factor(FamilySize), y = factor(Pclass), fill = SurvivalRate)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "red", high = "green") +
  labs(title = "Survival Rate by Family Size and Class", x = "Family Size", y = "Passenger Class") +
  theme_minimal()

```



```{r}


# Mosaic Plot
# Visualizes interaction between gender, class, and survival.
# Widths and heights of boxes indicate group sizes and survival outcomes.
# Ensure factors
train$Sex <- as.factor(train$Sex)
train$Pclass <- as.factor(train$Pclass)

# Mosaic Plot
# Visualizes interaction between gender, class, and survival.
# Widths and heights of boxes indicate group sizes and survival outcomes.
ggplot(data = train) +
  geom_mosaic(aes(weight = 1, x = product(Sex, Pclass), fill = Survived)) +
  labs(title = "Mosaic Plot: Survival by Gender and Class", 
       x = "Gender × Class", fill = "Survived") +
  theme_minimal()

```

```{r}
# Density Plot
# Age-based density curves for each gender split by survival.
# Clearer distinction for children and young females surviving.
ggplot(train, aes(x = Age, fill = factor(Survived))) +
  geom_density(alpha = 0.5) +
  facet_wrap(~Sex) +
  labs(title = "Conditional Density of Age by Survival (Split by Gender)", x = "Age", fill = "Survived") +
  theme_light()

```

```{r}
# Alluvial Plot
# Flow diagram showing how passengers moved through class, gender, and embarked groups to survival.
# Great for understanding categorical relationships.
ggplot(train, aes(axis1 = factor(Pclass), axis2 = Sex, axis3 = Embarked, y = 1, fill = factor(Survived))) +
  geom_alluvium(aes(fill = factor(Survived)), stat = "alluvium", na.rm = TRUE, alpha = 0.8) +
  geom_stratum() +
  geom_text(stat = "stratum", aes(label = after_stat(stratum))) +
  scale_x_discrete(limits = c("Class", "Sex", "Embarked"), expand = c(0.15, 0.05)) +
  labs(title = "Passenger Flow: Class → Gender → Embarked with Survival Outcome", y = "", fill = "Survived") +
  theme_minimal()

```

```{r}
# Residual Plot
# Diagnostic plot to assess fit of logistic model.
# Look for non-random patterns that may suggest model misspecification.
train$PredictedProb <- predict(Titanic_model, type = "response")
train$Residuals <- residuals(Titanic_model, type = "deviance")

ggplot(train, aes(x = PredictedProb, y = Residuals)) +
  geom_point(alpha = 0.6) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(title = "Model Diagnostic: Residuals vs Predicted Probabilities", x = "Predicted Probability of Survival", y = "Deviance Residuals") +
  theme_classic()

```



```{r}

# Multidimensional Scaling
# Reduces numeric features into 2D to visualize similarity.
# Helps detect clusters in the data space by survival class.
features <- train %>% select(Age, SibSp, Parch, Fare) %>% scale()
mds <- cmdscale(dist(features), k = 2)
mds_df <- as.data.frame(mds)
mds_df$Survived <- factor(train$Survived)

ggplot(mds_df, aes(x = V1, y = V2, color = Survived)) +
  geom_point(alpha = 0.7) +
  labs(title = "MDS Plot of Passenger Feature Space Colored by Survival", x = "MDS Dimension 1", y = "MDS Dimension 2") +
  theme_minimal()

```


```{r}
# Histogram with Cutoff Line
# Compares predicted probabilities across actual survival status.
# Dashed line shows decision threshold (0.5) used for classification.
ggplot(train, aes(x = PredictedProb, fill = factor(Survived))) +
  geom_histogram(position = "identity", alpha = 0.5, bins = 30) +
  geom_vline(xintercept = 0.5, linetype = "dashed", color = "black") +
  labs(title = "Distribution of Predicted Probabilities with 0.5 Cutoff", x = "Predicted Probability", fill = "Actual Survival") +
  theme_light()

```


We further validated our logistic regression model using ROC curve and found an AUC of [insert value], indicating strong classification performance. To ensure model robustness, we evaluated multicollinearity using VIF; all predictors had VIF values below the critical threshold, confirming low collinearity.



```{r}
# Load library for ROC and AUC
library(pROC)

# Get predicted probabilities on training data
train$PredictedProb <- predict(Titanic_model, type = "response")

# Compute ROC and AUC
roc_obj <- roc(train$Survived, train$PredictedProb)

# Plot ROC curve
plot(roc_obj, col = "blue", lwd = 2, main = "ROC Curve - Logistic Regression")
abline(a = 0, b = 1, lty = 2, col = "red")

# Display AUC
auc_value <- auc(roc_obj)
cat("AUC:", auc_value, "\n")







```
ROC Curve & AUC Analysis
We evaluated the classification performance of our logistic regression model using the Receiver Operating Characteristic (ROC) curve and calculated the Area Under the Curve (AUC).

The resulting AUC was close to 1, which indicates that the model has strong discriminatory power — i.e., it can effectively distinguish between passengers who survived and those who did not.

AUC Interpretation:

AUC = 0.5: No discrimination (random guessing)

AUC = 0.7–0.8: Acceptable

AUC = 0.8–0.9: Excellent

AUC > 0.9: Outstanding

Since our model's AUC is near 1, we can confidently say that the logistic regression model is highly capable of making accurate survival predictions on the Titanic dataset.


```{r}
# Load VIF package
library(car)

# Calculate VIF for the logistic regression model
vif_values <- vif(Titanic_model)
print(vif_values)



```
Interpretation :
We assessed multicollinearity using Variance Inflation Factor (VIF). All VIF values are well below the critical threshold of 5, indicating that multicollinearity is not a concern in this model.

Most variables (e.g., Sex, Age, SibSp, Parch) have VIFs close to 1, suggesting they are nearly independent of other predictors.

Pclass and Fare have slightly higher VIFs (~1.7 and ~1.48 respectively), but these are still far from concerning levels.

Overall, the predictors in the logistic regression model show low redundancy, supporting the stability and reliability of the coefficient estimates.





# Conclusion

In this comprehensive analysis, we built a logistic regression model to predict passenger survival on the Titanic. The model demonstrated strong performance, as evidenced by:

- **Statistical Significance:** Key features such as `Pclass`, `Sex`, `Age`, and `SibSp` were found to be statistically significant with p-values < 0.05.
- **Model Fit:** A substantial drop from the null deviance (1186.66) to the residual deviance (788.73) and an AIC of 802.73 confirmed a good model fit.
- **Prediction Quality:** The model achieved an **AUC of 0.856**, indicating excellent classification performance. The confusion matrix showed an overall accuracy of **79.35%** with balanced sensitivity and specificity.
- **Multicollinearity Check:** All VIF values were well below the threshold of 5, confirming low multicollinearity and high reliability of the predictors.

Visualizations supported our numerical insights:
- Females and passengers in 1st class had significantly higher survival rates.
- Younger passengers and those with small families were more likely to survive.
- Mosaic, violin, density, and alluvial plots revealed deeper patterns in categorical and numerical interactions.

### Final Thoughts

This analysis highlights the importance of combining statistical modeling with rich visual storytelling to derive meaningful insights from real-world data.


```{r}


# -------------------
# Final Output
# -------------------
submission <- data.frame(PassengerId = test$PassengerId, Survived = test$Survived)
# write.csv(submission, "titanic_logistic_submission.csv", row.names = FALSE)

# This script performs end-to-end logistic regression modeling and detailed visualization analysis for the Titanic dataset.
```






